{
 "metadata": {
  "name": "",
  "signature": "sha256:02765bfbe84d89ad4b86e9569f86eb06881b9129c83e7ee3c9bd74c95b852059"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 334
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "fn = 129\n",
      "text = ''.join(open('part-%d/%d' %(i,fn),'rb').readlines())\n",
      "# print text\n",
      "line = open('part-%05d' %i,'rb').readlines()[fn-1]\n",
      "print line\n",
      "sel = Selector(text=text)\n",
      "print sel.xpath('//div[@class=\"profile-overview-content\"]')\n",
      "print Selector(text=text).xpath('string(//div[@class=\"profile-overview-content\"]//span[@class=\"full-name\"])').extract()[0]\n",
      "sel = sel.xpath('//div[re:test(@id,\"education-(\\d+)-view\")]')\n",
      "print len(sel)\n",
      "print sel[0].xpath('string(.//h4[@class= \"summary fn org\"])').extract()[0].strip()\n",
      "print sel[0].xpath('string(.//span[@class=\"degree\"])').extract()[0].strip()\n",
      "print sel[0].xpath('string(.//span[@class=\"major\"])').extract()[0].strip()\n",
      "print sel[0].xpath('string(.//span[@class=\"education-date\"])').extract()[0].split()[0]\n",
      "print sel[0].xpath('string(.//span[@class=\"education-date\"])').extract()[0].split()[-1]\n",
      "converter = html2text.HTML2Text()\n",
      "converter.ignore_links = True\n",
      "print ','.join(filter(None, converter.handle(sel[0].extract()).split('\\n')))\n",
      "print sel[0].xpath('string(.)').extract()\n",
      "print ','.join(filter(None, sel[0].xpath('.//text()').extract()[0].split('\\n')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.linkedin.com/in/babettewalter\tlaborer\tlogistics_and_supply_chain\tjenkintown,_pennsylvania\ttemple_university community_college_of_philadelphia\tbachelor's_degree,_accounting_and_finance liberal_arts_degree,_business,_management\t2008 1994_\u2013_2008\tbabettes_tax_office united_postal_service\ttax_professional laborer\t(12_years_5_months) (8_years)\t5323_frankford_ave_philadelphia,_pa_19046\t\t\t13\t\t\n",
        "\n",
        "[<Selector xpath='//div[@class=\"profile-overview-content\"]' data=u'<div class=\"profile-overview-content\"><d'>]\n",
        "Babette Walter\n",
        "2\n",
        "Community College of Philadelphia\n",
        "Liberal Arts degree,\n",
        "Business, Management\n",
        "1994\n",
        "2008\n",
        "##### ![Community College of Philadelphia](http://m.c.lnkd.licdn.com/mpr/mpr/s,hrink_60_60/p/6/005/020/118/38d4445.png),#### Community College of Philadelphia,##### Liberal Arts degree, Business, Management,1994 \u2013 2008\n",
        "[u'Community College of PhiladelphiaLiberal Arts degree, Business, Management1994 \\u2013 2008']\n",
        "Community College of Philadelphia\n"
       ]
      }
     ],
     "prompt_number": 436
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "fn = 1085\n",
      "\n",
      "text = ''.join(open('part-%d/%d' %(i,fn),'rb').readlines())\n",
      "# print text\n",
      "line = open('part-%05d' %i,'rb').readlines()[fn-1]\n",
      "print line\n",
      "from scrapy.selector import Selector\n",
      "import html2text\n",
      "sel = Selector(text=text)\n",
      "sel\n",
      "# sel.css('.-header')\n",
      "# sel.xpath('//div[@class=\"profile-overview-content\"]')\n",
      "print Selector(text=text).xpath('string(//div[@class=\"profile-header\"]//span[@class=\"full-name\"])').extract()[0]\n",
      "sel = sel.xpath('//div[@id=\"profile-education\"]//div[starts-with(@class,\"position\")]')\n",
      "print sel[0].xpath('string(.//h3[@class= \"summary fn org\"])').extract()[0].strip()\n",
      "print sel[0].xpath('string(.//h4[@class=\"details-education\"]//span[@class=\"degree\"])').extract()[0].strip()\n",
      "print sel[0].xpath('string(.//h4[@class=\"details-education\"]//span[@class=\"major\"])').extract()[0].strip()\n",
      "print sel[0].xpath('string(.//abbr[@class=\"dtstart\"]//@title)').extract()[0].split('-')[0]\n",
      "print sel[0].xpath('string(.//abbr[@class=\"dtend\"]//@title)').extract()[0].split('-')[1]\n",
      "print sel[0].xpath('string(.//p[@class=\"desc details-education\"])').extract()[0].strip()\n",
      "converter = html2text.HTML2Text()\n",
      "converter.ignore_links = True\n",
      "print ','.join(filter(None, converter.handle(sel[0].extract()).split('\\n')))\n",
      "print ','.join(filter(None, sel[0].xpath('string(.)').extract()[0].split('\\n')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.linkedin.com/in/matthewpuscar\tsecurities_lending_operations_vp\tinvestment_management\tking_of_prussia,_pennsylvania\ttemple_university st_joseph_s_university\t \tfebruary_1999_\u2013_september_2001 january_2003_\u2013_december_2005\tinfonautics pnc_advisors sei_investments bnp_paribas jpmorgan_chase_bank_na\tsecurities_lending_operations_vp\t(5_years) (2_years) (4_years) (1_year_11_months) (5_years_1_month)\t\tcorporate_actions securities securities_lending options derivatives equities fixed_income management bloomberg financial_services back_office settlement collateral_management investment_banking dtc operational_risk global_custody swift_payments corporate_finance bloomberg_terminal equity_derivatives asset_managment middle_office investments alternative_investments bonds operational_risk_management\t\t440\t\tresults_oriented_professional_with_a_solid_background_in_investment_processing_analysis_and_development._experienced_in_strategic_planning,_efficiency_analysis,_and_management_of_daily_investment_processing._skilled_in_developing_and_implementing_standardized_policies_and_procedures.\n",
        "\n",
        "\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-505-b48b7819a9f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mSelector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string(//div[@class=\"profile-header\"]//span[@class=\"full-name\"])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0msel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div[@id=\"profile-education\"]//div[starts-with(@class,\"position\")]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string(.//h3[@class= \"summary fn org\"])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string(.//h4[@class=\"details-education\"]//span[@class=\"degree\"])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string(.//h4[@class=\"details-education\"]//span[@class=\"major\"])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 505
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scrapy.selector import Selector\n",
      "for i in range(0,10):\n",
      "# for i in [0]:\n",
      "    infn = 'part-%05d' %(i)\n",
      "    orig = open('part-%05d' %(i)).readlines()\n",
      "    names = open('part-%05d-namemap' %(i)).readlines()\n",
      "    assert(len(orig) == len(names))\n",
      "#     outfn = infn + '-edudf'\n",
      "#     outputfile = codecs.open(outfn,encoding='utf-8', mode='w+')\n",
      "    linenum = 0\n",
      "    edudf = pd.DataFrame()\n",
      "    edudict = {}\n",
      "    edudict['Index'] = []\n",
      "    edudict['FullName'] = []\n",
      "    edudict['FirstName'] = []\n",
      "    edudict['LastName'] = []\n",
      "    edudict['University'] = []\n",
      "    edudict['Degree'] = []\n",
      "    edudict['Major'] = []\n",
      "    edudict['StartYear'] = []\n",
      "    edudict['StartMonth'] = []\n",
      "    edudict['EndYear'] = []\n",
      "    edudict['EndMonth'] = []\n",
      "    edudict['Desc'] = []\n",
      "    edudict['Text'] = []\n",
      "    \n",
      "    for ln in range(0,len(orig)):\n",
      "#     for ln in [128]:\n",
      "#         print \"%d, %d\" %(i, ln)\n",
      "        pro_file = ''.join(open('part-%d/%d' %(i,ln+1),'rb').readlines())\n",
      "        sel = Selector(text=pro_file)\n",
      "        if sel.xpath('//div[@class=\"profile-header\"]'):\n",
      "        # Template 1\n",
      "            fullname = sel.xpath('string(//div[@class=\"profile-header\"]//span[@class=\"full-name\"])').extract()[0]\n",
      "            firstname = sel.xpath('string(//div[@class=\"profile-header\"]//span[@class=\"given-name\"])').extract()[0]\n",
      "            lastname = sel.xpath('string(//div[@class=\"profile-header\"]//span[@class=\"family-name\"])').extract()[0]\n",
      "            education = sel.xpath('//div[@id=\"profile-education\"]//div[starts-with(@class,\"position\")]')\n",
      "            for edu in education:\n",
      "#                 print ln\n",
      "                edudict['Index'].append(ln)\n",
      "                edudict['FullName'].append(fullname)\n",
      "                edudict['FirstName'].append(firstname)\n",
      "                edudict['LastName'].append(lastname)\n",
      "                edudict['University'].append(edu.xpath('string(.//h3[@class= \"summary fn org\"])').extract()[0].strip())\n",
      "                edudict['Degree'].append(edu.xpath('string(.//h4[@class=\"details-education\"]//span[@class=\"degree\"])').extract()[0].strip())\n",
      "                edudict['Major'].append(edu.xpath('string(.//h4[@class=\"details-education\"]//span[@class=\"major\"])').extract()[0].strip())\n",
      "                starttime = edu.xpath('string(.//abbr[@class=\"dtstart\"]//@title)').extract()[0] \n",
      "                if starttime:\n",
      "                    edudict['StartYear'].append(starttime.split('-')[0])\n",
      "                    edudict['StartMonth'].append(starttime.split('-')[1])\n",
      "                else:\n",
      "                    edudict['StartYear'].append('')\n",
      "                    edudict['StartMonth'].append('')\n",
      "                    \n",
      "                endtime = edu.xpath('string(.//abbr[@class=\"dtend\"]//@title)').extract()[0]\n",
      "                if endtime:\n",
      "                    edudict['EndYear'].append(endtime.split('-')[0])\n",
      "                    edudict['EndMonth'].append(endtime.split('-')[1])\n",
      "                else:\n",
      "                    edudict['EndYear'].append('')\n",
      "                    edudict['EndMonth'].append('')\n",
      "                edudict['Desc'].append(','.join(filter(None, \\\n",
      "                                    edu.xpath('string(.//p[@class=\"desc details-education\"])').extract()[0].split('\\n'))))\n",
      "                edudict['Text'].append(','.join(filter(None, edu.xpath('string(.)').extract()[0].split('\\n'))))\n",
      "                \n",
      "        elif sel.xpath('//div[@class=\"profile-overview-content\"]'):\n",
      "        # Template 2\n",
      "            fullname = sel.xpath('string(//div[@class=\"profile-overview-content\"]//span[@class=\"full-name\"])').extract()[0]\n",
      "            firstname = fullname.split()[0]\n",
      "            lastname = ' '.join(fullname.split()[1:])\n",
      "            education = sel.xpath('//div[re:test(@id,\"education-(\\d+)-view\")]')\n",
      "            for edu in education:\n",
      "#                 print ln\n",
      "                edudict['Index'].append(ln)\n",
      "                edudict['FullName'].append(fullname)\n",
      "                edudict['FirstName'].append(firstname)\n",
      "                edudict['LastName'].append(lastname)\n",
      "                edudict['University'].append(edu.xpath('string(.//h4[@class= \"summary fn org\"])').extract()[0].strip())\n",
      "                edudict['Degree'].append(edu.xpath('string(.//span[@class=\"degree\"])').extract()[0].strip())\n",
      "                edudict['Major'].append(edu.xpath('string(.//span[@class=\"major\"])').extract()[0].strip())\n",
      "                duration = edu.xpath('.//span[@class=\"education-date\"]//time')\n",
      "#                 duration = edu.xpath('string(.//span[@class=\"education-date\"])').extract()[0]\n",
      "                if len(duration) == 2:\n",
      "                    edudict['StartYear'].append(duration[0].xpath('string(.)').extract()[0].strip().split()[-1])\n",
      "                    edudict['StartMonth'].append(1)\n",
      "                    edudict['EndYear'].append(duration[1].xpath('string(.)').extract()[0].strip().split()[-1])\n",
      "                    edudict['EndMonth'].append(12)\n",
      "                elif len(duration) == 1:\n",
      "                    edudict['StartYear'].append('')\n",
      "                    edudict['StartMonth'].append('')\n",
      "                    edudict['EndYear'].append(duration[0].xpath('string(.)').extract()[0].strip().split()[-1])\n",
      "                    edudict['EndMonth'].append(12)\n",
      "                else:\n",
      "                    edudict['StartYear'].append('')\n",
      "                    edudict['EndYear'].append('')\n",
      "                    edudict['StartMonth'].append('')\n",
      "                    edudict['EndMonth'].append('')\n",
      "                edudict['Desc'].append('')\n",
      "                converter = html2text.HTML2Text()\n",
      "                converter.ignore_links = True\n",
      "                edudict['Text'].append(','.join(filter(None, converter.handle(edu.extract()).split('\\n'))))\n",
      "        else:\n",
      "        # No html page extracted\n",
      "            schools = orig[ln].split('\\t')[4].split()\n",
      "            degrees = orig[ln].split('\\t')[5].split()\n",
      "            durations = orig[ln].split('\\t')[6].split()\n",
      "#             print schools, degrees, durations\n",
      "#             print len(schools),len(degrees),len(durations)\n",
      "            if (len(schools) != len(degrees)) or (len(schools) != len(durations)) or (len(degrees) != len(durations)):\n",
      "#                 print 'Exception: fail to get the years and educations %d, file %d' %(i,ln)\n",
      "                linenum += 1\n",
      "            else:\n",
      "#                 print ln\n",
      "                for count in range(len(schools)):\n",
      "                    edudict['Index'].append(ln)\n",
      "                    edudict['FullName'].append('')\n",
      "                    edudict['FirstName'].append('')\n",
      "                    edudict['LastName'].append('')\n",
      "                    edudict['University'].append(schools[count])\n",
      "                    edudict['Degree'].append(degrees[count])\n",
      "                    edudict['Major'].append('')\n",
      "                    edudict['StartYear'].append(durations[count].split('_')[0])\n",
      "                    edudict['StartMonth'].append(1)\n",
      "                    edudict['EndYear'].append(durations[count].split('_')[-1])\n",
      "                    edudict['EndMonth'].append(12)\n",
      "                    edudict['Desc'].append('')\n",
      "                    edudict['Text'].append(','.join([schools[count],degrees[count],durations[count]]))\n",
      "    \n",
      "    cols=['Index','FullName','FirstName','LastName','University','Major','Degree',\\\n",
      "                                'StartYear','StartMonth','EndYear','EndMonth',\\\n",
      "                                'Desc','Text']\n",
      "    for name in cols:\n",
      "        print len(edudict[name])\n",
      "    \n",
      "    edudf = pd.DataFrame(edudict)\n",
      "    edudf.to_csv('part-%05d-education.csv' %i, sep='\\t', index=False, encoding='utf-8', cols=cols)\n",
      "    print linenum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "18948\n",
        "124"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "18588\n",
        "117"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18790"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "18790\n",
        "96"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18980"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "18980\n",
        "124"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18703"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "18703\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18845"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "18845\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19297"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "19297\n",
        "110"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18743"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "18743\n",
        "105"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18635"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "18635\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19073"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "19073\n",
        "118"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 506
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0,10):\n",
      "    infn = 'part-%05d' %(i)\n",
      "    orig = open('part-%05d' %(i)).readlines()\n",
      "    metaInfo = {}\n",
      "    cols = ['Index','UserID','CurrPosition','Industry','CurrLocation','Skills','Hobbies','Num_of_Conn','Languages','Summary']\n",
      "    inds = [0,1,2,3,11,12,13,14,15]\n",
      "    j = 0\n",
      "    for col in cols:\n",
      "        if col == 'Index':\n",
      "            metaInfo[col] = [ln for ln,x in enumerate(orig)]\n",
      "        else:\n",
      "            metaInfo[col] = [x.split('\\t')[inds[j]] for x in orig]\n",
      "            j +=1\n",
      "    metaInfo = pd.DataFrame(metaInfo)\n",
      "    metaInfo.to_csv('part-%05d-metainfo.csv' %i, encoding='utf-8',cols=cols,index=False,sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 359
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "i = 0\n",
      "fn = 1\n",
      "text = ''.join(open('part-%d/%d' %(i,fn),'rb').readlines())\n",
      "# print text\n",
      "line = open('part-%05d' %i,'rb').readlines()[fn-1]\n",
      "print line\n",
      "sel = Selector(text=text)\n",
      "print sel.xpath('//div[@class=\"profile-overview-content\"]')\n",
      "print Selector(text=text).xpath('string(//div[@class=\"profile-overview-content\"]//span[@class=\"full-name\"])').extract()[0]\n",
      "sel = sel.xpath('//div[re:test(@id,\"experience-(\\d+)-view\")]')\n",
      "print len(sel)\n",
      "print sel[0].xpath('string(.//h4)').extract()[0].strip()\n",
      "print sel[0].xpath('.//h5')[-1].xpath('string(.)').extract()[0].strip()\n",
      "print sel[0].xpath('string(.//span[@class=\"locality\"])').extract()[0].strip()\n",
      "time = sel[0].xpath('.//span[@class=\"experience-date-locale\"]//time') \n",
      "\n",
      "st = time[0].xpath('string(.)').extract()[0].split()\n",
      "print st[-1]\n",
      "if len(st) == 2:\n",
      "    print st[0]\n",
      "else:\n",
      "    print 'January'\n",
      "timestr = sel[0].xpath('.//span[@class=\"experience-date-locale\"]').xpath('string(.)').extract()[0]\n",
      "print timestr\n",
      "print re.search(\"\\((.*?)\\)\", timestr).group(1)\n",
      "print sel[0].xpath('string(.//span[@class=\"experience-date-locale\"])').extract()[0].split()[0]\n",
      "print sel[0].xpath('string(.//span[@class=\"experience-date-locale\"])').extract()[0].split()[-1]\n",
      "converter = html2text.HTML2Text()\n",
      "converter.ignore_links = True\n",
      "print ','.join(filter(None,sel[0].xpath('string(.//p[@class=\"description\"])').extract()[0].split('\\n')))\n",
      "# print ','.join(filter(None, converter.handle(sel[0].xpath('.//p[@class=\"description\"]')[0].extract()).split('\\n')))\n",
      "# print ','.join(filter(None, converter.handle(sel[0].extract()).split('\\n')))\n",
      "# print sel[0].xpath('string(.)').extract()\n",
      "# print ','.join(filter(None, sel[0].xpath('.//text()').extract()[0].split('\\n')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.linkedin.com/in/1neff\tcorporate_market_sales_consultant\tinformation_services\tgreater_new_york_city_area\ttemple_university_fox_school_of_business_and_management\t bachelor_of_business_administration_(bba),_marketing_&amp;_human_resource_administration\t\tlanier_worldwide compliance_international candle_corporation complinet thomson_west thomson_reuters\tcorporate_market_sales_consultant\t(1_year) (3_years) (2_years) (less_than_a_year) (4_years) (7_years_5_months)\tnew_jersey\tsales strategy saas direct_sales bb account_management cold_calling sales_process business_development selling new_business_development sales_presentations leadership strategic_planning professional_services strategic_partnerships lead_generation sales_management crm integration solution_selling enterprise_software salesforcecom cloud_computing management\ttrivia, travel, food, garage sales, memorabilia, watches, philadelphia phillies, eagles, sixers, personal development,\t500+\t\tconsultative_sales_professional_with_over_20_years_of_success._my_experience_and_focus_is_within_information_services,_solutions,_software,_technology,_electronic_publishing_&amp;_content_and_online_legal_research._experience_includes_selling_directly_to_numerous_industries,_verticals_&amp;_company\u2019s_which_range_from_small_business\u2019s_to_fortune_500_corporations._the_past_11_years_with_thomson_reuters_i_have_sold_to_both_law_firms_and_corporations._the_primary_focus_has_been_consulting_with_corporate_legal_departments_and_general_counsel._my_experience_also_includes_servicing_professionals_in_compliance,_intellectual_property,_government_affairs,_corporate_security_&amp;_investigations_and_as_well_as_other_departments.\n",
        "\n",
        "[<Selector xpath='//div[@class=\"profile-overview-content\"]' data=u'<div class=\"profile-overview-content\"><d'>]\n",
        "David L. Neff\n",
        "6\n",
        "Corporate Market Sales Consultant\n",
        "Thomson Reuters\n",
        "New Jersey\n",
        "2007\n",
        "January\n",
        "January 2007 \u2013 Present (7 years 10 months)New Jersey\n",
        "7 years 10 months\n",
        "January\n",
        "Jersey\n",
        "I help General Counsel & Legal Departments provide value to their organizations by educating them on how to become more efficient, reduce outside expenses and mitigate risk with our technology and SaaS solutions. Some Highlights of our current solutions now include:,\u25ba WestlawNext - the industry\u2019s premier and universally recognized leading provider of online legal research.,\u25ba Practical Law is the industry\u2019s leading provider of legal know-how to start and handle various projects with checklists, standard documents and other resources from our practice area experts.,\u25ba Concourse Matter Room & Legal Hold help companies reduce risk with a repeatable, automated and defensible solution. Matter Room is a secure cloud based collaboration and organization solution.,\u25ba West LegalEdCenter \u2013 is the industry's largest content collection and aggregator for professional development and online Continuing Legal Education (CLE). ,Our product mix is always changing. I\u2019ve worked with many other offerings which include:,\u25ba e-billing and matter management with Serengeti.,\u25ba IP Intelligence, analytics and research from Thomson Innovation. ,\u25ba Due Diligence and investigative solutions with PeopleMap, CLEAR and our public / criminal records (OFAC lists) of people and companies.,\u25ba By acquiring many companies it has provided me the chance to collaborate and work in a team selling environment with some great people. ,\u25ba Consistently overachieved expectations with new sales quota and renewal and revenue retention goals.,\u25ba Leader within the sales team. Chosen to participate in three separate pilot programs, including: the launch of WestlawNext, Social Media & elected to our Advisory Board. Frequently strategized with the marketing and product development teams.\n"
       ]
      }
     ],
     "prompt_number": 484
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "fn = 27\n",
      "text = ''.join(open('part-%d/%d' %(i,fn),'rb').readlines())\n",
      "# print text\n",
      "line = open('part-%05d' %i,'rb').readlines()[fn-1]\n",
      "print line\n",
      "from scrapy.selector import Selector\n",
      "import html2text\n",
      "sel = Selector(text=text)\n",
      "sel\n",
      "# sel.css('.-header')\n",
      "# sel.xpath('//div[@class=\"profile-overview-content\"]')\n",
      "print Selector(text=text).xpath('string(//div[@class=\"profile-header\"]//span[@class=\"full-name\"])').extract()[0]\n",
      "sel = sel.xpath('//div[@id=\"profile-experience\"]//div[starts-with(@class,\"position\")]')\n",
      "print sel[0].xpath('string(.//span[@class=\"org summary\"])').extract()[0].strip()\n",
      "print sel[0].xpath('string(.//span[@class= \"title\"])').extract()[0].strip()\n",
      "print ','.join(filter(None,sel[0].xpath('string(.//p[starts-with(@class,\" description\")])').extract()[0].split('\\n')))\n",
      "\n",
      "print sel[0].xpath('string(.//abbr[@class=\"dtstart\"]//@title)').extract()[0].split('-')[0]\n",
      "# print sel[0].xpath('string(.//abbr[@class=\"dtend\"]//@title)').extract()[0].split('-')[1]\n",
      "converter = html2text.HTML2Text()\n",
      "converter.ignore_links = True\n",
      "# print ','.join(filter(None, converter.handle(sel[0].xpath('.//p[starts-with(@class,\" description\")]')[0].extract()).split('\\n')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.linkedin.com/in/alanpoland\t\tpublic_relations_and_communications\twilmington,_delaware\tlebanon_valley_college temple_university university_of_kansas\thigh_school_dipoloma,_academic/business freshman_year_only various_evening_courses sophmore_year bs_journalism,_journalism\t1952_\u2013_1962 1962_\u2013_1963 1963_\u2013_1963 1964_\u2013_1965 1965_\u2013_1967\tthe_kansas_city_star wilmington_de_news_journal delaware_state_public_safety ici reese_tomases_amp_ellick produce_marketing_association\t\t(1_year_4_months) (2_years_5_months) (3_years_6_months) (3_years_5_months) (26_years_8_months) (1_year_6_months)\t\tmedia_relations copywriting press_releases photography nonprofits public_relations marketing_communications event_planning advertising management strategy corporate_communications strategic_communications crm crisis_communications social_media email_marketing social_media_marketing integrated_marketing social_networking blogging newsletters event_management online_marketing fundraising direct_marketing editing marketing_strategy project_management marketing internal_communications journalism creative_direction copy_editing brand_development\t\t217\t\tnearly_forty_years_of_professional_experience_in_journalism,_public_relations,_advertising_and_marketing_communications._now_retired.\n",
        "\n",
        "\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-497-c5d4ac00adbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mSelector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string(//div[@class=\"profile-header\"]//span[@class=\"full-name\"])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0msel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div[@id=\"profile-experience\"]//div[starts-with(@class,\"position\")]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string(.//span[@class=\"org summary\"])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string(.//span[@class= \"title\"])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string(.//p[starts-with(@class,\" description\")])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 497
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scrapy.selector import Selector\n",
      "cols = ['Index','Company','Position','StartYear','StartMonth','EndYear','EndMonth','Duration','Location','Desc']\n",
      "for i in range(1,10):\n",
      "# for i in [0]:\n",
      "    infn = 'part-%05d' %(i)\n",
      "    orig = open('part-%05d' %(i)).readlines()\n",
      "    names = open('part-%05d-namemap' %(i)).readlines()\n",
      "    assert(len(orig) == len(names))\n",
      "#     outfn = infn + '-edudf'\n",
      "#     outputfile = codecs.open(outfn,encoding='utf-8', mode='w+')\n",
      "    linenum = 0\n",
      "    edudf = pd.DataFrame()\n",
      "    edudict = {}\n",
      "    for col in cols:\n",
      "        edudict[col] = []\n",
      "    \n",
      "    for ln in range(0,len(orig)):\n",
      "#     for ln in [0]:\n",
      "#         print \"%d, %d\" %(i, ln)\n",
      "        pro_file = ''.join(open('part-%d/%d' %(i,ln+1),'rb').readlines())\n",
      "        sel = Selector(text=pro_file)\n",
      "        if sel.xpath('//div[@class=\"profile-header\"]'):\n",
      "            # Template 1\n",
      "            experience = sel.xpath('//div[@id=\"profile-experience\"]//div[starts-with(@class,\"position\")]')\n",
      "            for edu in experience: \n",
      "                edudict['Index'].append(ln)\n",
      "                edudict['Company'].append(edu.xpath('string(.//span[@class=\"org summary\"])').extract()[0].strip())\n",
      "                edudict['Position'].append(edu.xpath('string(.//span[@class= \"title\"])').extract()[0].strip())\n",
      "\n",
      "                starttime = edu.xpath('string(.//abbr[@class=\"dtstart\"]//@title)').extract()[0] \n",
      "                if starttime:\n",
      "                    edudict['StartYear'].append(starttime.split('-')[0])\n",
      "                    try:\n",
      "                        edudict['StartMonth'].append(starttime.split('-')[1])\n",
      "                    except IndexError:\n",
      "                        edudict['StartMonth'].append('')\n",
      "                else:\n",
      "                    edudict['StartYear'].append('')\n",
      "                    edudict['StartMonth'].append('')\n",
      "\n",
      "                endtime = edu.xpath('string(.//abbr[@class=\"dtend\"]//@title)').extract()[0]\n",
      "                if endtime:\n",
      "                    edudict['EndYear'].append(endtime.split('-')[0])\n",
      "                    try:\n",
      "                        edudict['EndMonth'].append(endtime.split('-')[1])\n",
      "                    except IndexError:\n",
      "                        edudict['EndMonth'].append('')\n",
      "                elif edu.xpath('string(.//abbr[@class=\"dtstamp\"]//@title)').extract()[0]:\n",
      "                    edudict['EndYear'].append(2014)\n",
      "                    edudict['EndMonth'].append('')\n",
      "                else:\n",
      "                    edudict['EndYear'].append('')\n",
      "                    edudict['EndMonth'].append('')\n",
      "                edudict['Duration'].append(edu.xpath('string(.//span[@class=\"duration\"])').extract()[0].strip())\n",
      "                edudict['Location'].append(edu.xpath('string(.//span[@class=\"location\"])').extract()[0].strip())\n",
      "                desc = ','.join(filter(None,edu.xpath('string(.//p[starts-with(@class,\" description\")])').extract()[0].split('\\n')))\n",
      "                edudict['Desc'].append(desc)\n",
      "                \n",
      "        elif sel.xpath('//div[@class=\"profile-overview-content\"]'):\n",
      "        # Template 2\n",
      "#             fullname = sel.xpath('string(//div[@class=\"profile-overview-content\"]//span[@class=\"full-name\"])').extract()[0]\n",
      "#             firstname = fullname.split()[0:1]\n",
      "#             lastname = ' '.join(fullname.split()[1:])\n",
      "            experience = sel.xpath('//div[re:test(@id,\"experience-(\\d+)-view\")]')\n",
      "            for edu in experience:\n",
      "                edudict['Index'].append(ln)\n",
      "                edudict['Company'].append(edu.xpath('.//h5')[-1].xpath('string(.)').extract()[0].strip())\n",
      "                edudict['Position'].append(edu.xpath('string(.//h4)').extract()[0].strip())\n",
      "                time = edu.xpath('.//span[@class=\"experience-date-locale\"]//time') \n",
      "                try:\n",
      "                    st = time[0].xpath('string(.)').extract()[0].split()\n",
      "                except IndexError:\n",
      "                    edudict['StartYear'].append('')\n",
      "                    edudict['StartMonth'].append('')\n",
      "                    edudict['EndYear'].append('')\n",
      "                    edudict['EndMonth'].append('')\n",
      "                else:\n",
      "                    edudict['StartYear'].append(st[-1])\n",
      "                    if len(st) == 2:\n",
      "                        edudict['StartMonth'].append(st[0])\n",
      "                    else:\n",
      "                        edudict['StartMonth'].append('January')\n",
      "\n",
      "                    if len(time) == 2:\n",
      "                        end = time[1].xpath('string(.)').extract()[0].split()\n",
      "                        edudict['EndYear'].append(end[-1])\n",
      "                        if len(end) == 2:\n",
      "                            edudict['EndMonth'].append(end[0])\n",
      "                        else:\n",
      "                            edudict['EndMonth'].append('December')\n",
      "                    else:\n",
      "                        edudict['EndYear'].append('Present')\n",
      "                        edudict['EndMonth'].append('')\n",
      "                \n",
      "                timestr = edu.xpath('string(.//span[@class=\"experience-date-locale\"])').extract()[0]\n",
      "                \n",
      "                match = re.search(r\"\\((.*?)\\)\", timestr)\n",
      "                if match:\n",
      "                    edudict['Duration'].append(match.group(1))\n",
      "                else:\n",
      "                    edudict['Duration'].append('')\n",
      "                edudict['Location'].append(edu.xpath('string(.//span[@class=\"locality\"])').extract()[0].strip())\n",
      "                converter = html2text.HTML2Text()\n",
      "                converter.ignore_links = True\n",
      "                desc = ','.join(filter(None,edu.xpath('string(.//p[@class=\"description\"])').extract()[0].split('\\n')))\n",
      "                edudict['Desc'].append(desc)\n",
      "        else:\n",
      "#                 print 'Exception: fail to get the years and educations %d, file %d' %(i,ln)\n",
      "                linenum += 1\n",
      "    for name in cols:\n",
      "        print len(edudict[name])\n",
      "    \n",
      "    edudf = pd.DataFrame(edudict, columns= cols)\n",
      "#     print edudf\n",
      "    edudf.to_csv('part-%05d-experience.csv' %i, sep='\\t', index=False, encoding='utf-8', cols=cols)\n",
      "    print linenum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "36934\n",
        "36934\n",
        "36934\n",
        "36934\n",
        "36934\n",
        "36934\n",
        "36934\n",
        "36934\n",
        "36934\n",
        "36934\n",
        "217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37374"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37374\n",
        "37374\n",
        "37374\n",
        "37374\n",
        "37374\n",
        "37374\n",
        "37374\n",
        "37374\n",
        "37374\n",
        "202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37817"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37817\n",
        "37817\n",
        "37817\n",
        "37817\n",
        "37817\n",
        "37817\n",
        "37817\n",
        "37817\n",
        "37817\n",
        "216"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36987"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36987\n",
        "36987\n",
        "36987\n",
        "36987\n",
        "36987\n",
        "36987\n",
        "36987\n",
        "36987\n",
        "36987\n",
        "201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36905"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36905\n",
        "36905\n",
        "36905\n",
        "36905\n",
        "36905\n",
        "36905\n",
        "36905\n",
        "36905\n",
        "36905\n",
        "203"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37853"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37853\n",
        "37853\n",
        "37853\n",
        "37853\n",
        "37853\n",
        "37853\n",
        "37853\n",
        "37853\n",
        "37853\n",
        "215"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36886"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36886\n",
        "36886\n",
        "36886\n",
        "36886\n",
        "36886\n",
        "36886\n",
        "36886\n",
        "36886\n",
        "36886\n",
        "211"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37320"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37320\n",
        "37320\n",
        "37320\n",
        "37320\n",
        "37320\n",
        "37320\n",
        "37320\n",
        "37320\n",
        "37320\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38396"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38396\n",
        "38396\n",
        "38396\n",
        "38396\n",
        "38396\n",
        "38396\n",
        "38396\n",
        "38396\n",
        "38396\n",
        "233"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 502
    }
   ],
   "metadata": {}
  }
 ]
}